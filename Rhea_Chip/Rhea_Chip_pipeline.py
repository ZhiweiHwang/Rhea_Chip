#! /usr/bin/env python2.7
# -*- coding: utf-8 -*-
# The MIT License (MIT)
# Copyright (c) 2015 Joey Hwong
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and
# associated documentation files (the "Software"), to deal in the Software without restriction,
# including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense,
# and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so,
# subject to the following conditions: The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT
# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

"""
###############################################################################

Rhea_Chip.py
A Simple pipeline for the analysis of human data generated by NGS approaches.
usage: Rhea_Chip.py [-h] [--version] --samplelist [samplelist] --config [config.json] [options]
Expected arguments:
  -s, --samplelist     [FILE]  the sample list file
                       Column 1:        sample name
                       Column 2:        family name
                       Column 3:        FQ file [formact: lane1/fq1:lane1/adapter1;lane1/fq2:lane1/adapter2|lane2/fq1:lane2/adapter1;lane2/fq2:lane2/adapter2]
                       Column 4:        case/control
  -c, --config         [FILE]  the config file, contain all specific settings in a json file
Optional arguments:
  -h, --help           show this help message and exit
  --version        show program's version number and exit
  -m, --mode  [STR]    Fam for family analysis, Single for single analysis
  -o, --out   [STR]    the output dir

###############################################################################
"""
import logging
import random
import string
from optparse import OptionParser, OptionGroup
import Rhea_Chip
from collections import namedtuple
from Rhea_Chip.lib import *
from Rhea_Chip.lib.CreateFolder import FolderMaker, mksymlink
from Rhea_Chip.lib.ParserConfig import ParserConfig

Rhea_Chip_Home = os.getenv('Rhea_Chip_Home') or os.path.dirname(os.path.abspath(__file__))
assert Rhea_Chip_Home and os.path.isdir(Rhea_Chip_Home), Rhea_Chip.__note__
TempPath = tempfile.mkdtemp()
LogFile = os.path.join(TempPath, 'Rhea_Cdhip.log')
logger = logging.getLogger(__name__)
logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s', filename=LogFile, level=logging.INFO)
logger.info('Running: python %s' % ' '.join(sys.argv))


class SampleMessageParser(object):
	def __init__(self, files):
		self.samplelist = os.path.abspath(files)
		self.family = defaultdict(set)
		self.messages = dict(self.get_raw_message())

	def get_raw_message(self):
		unit_id = "".join(random.sample(string.ascii_uppercase, 2) + random.sample(string.digits, 4))
		name_tuple = namedtuple('SampleMessage', ("Sample", "Family", "Library", "fq", "Type", "Unit"))
		with smart_open(self.samplelist) as f_in:
			for lines in f_in:
				rows = lines.strip().split()
				if len(rows) < 5:
					logger.info("Ignore sample message from %s" % lines.strip())
					continue
				fastq = namedtuple('fastq', ("SequenceType", "SequenceData"))
				seq_data = defaultdict(list)
				samplename, samplefamily, library, samplefq, sampletype = rows[:5]
				if samplefamily == ".":
					samplefamily = samplename
				self.family[samplefamily].add(samplename)
				lanes = samplefq.split("|")
				seq_type = 'PE' if len(lanes[0].split(";")) == 2 else 'SE'
				for lane_number in xrange(len(lanes)):
					fastqs = lanes[lane_number].split(";")
					if len(fastqs) > 2:
						raise IOError('Sample %s has more than two fastqs ?' % samplename)
					if (len(fastqs) == 2 and seq_type == 'SE') or (len(fastqs) == 1 and seq_type == 'PE'):
						raise IOError('Sample %s has a different number of the fastqs ?' % samplename)
					for fq in fastqs:
						fqs = fq.split(":")
						if len(fqs) == 2:
							s_d, s_a = fqs
						else:
							s_d, s_a = fqs[0], ""
						seq_data[lane_number + 1].append((s_d, s_a))
				fastq_message = fastq._make((seq_type, seq_data))
				messages = name_tuple._make((samplename, samplefamily, library, fastq_message, sampletype, unit_id))
				yield (samplename, messages)

	def __len__(self):
		return len(self.messages.keys())

	def __iter__(self):
		return iter(self.messages.iteritems())


class Pipeline(object):
	"""
	create all scripts for analysis
	"""

	def __init__(self, sample_messages, sample_workdirs, conf):
		self.workdir = sample_workdirs
		self.messages = sample_messages
		self.sample = self.messages.Sample
		self.conf = conf
		self.log = os.path.join(self.workdir.Script, "../log")
		self.final_tsv = list()

	def get_scripts(self, jobs):
		if 'filter' in jobs:
			self.Step1_Filter()
		if 'alignment' in jobs:
			self.Step2_Alignment()
		if 'merge' in jobs:
			self.Step3_MergeBam()
		if 'removeduplicates' in jobs:
			self.Step4_removeduplicates()
		if 'realignertargetcreator' in jobs:
			self.Step5_RealignerTargetCreator()
		if 'indelrealigner' in jobs:
			self.Step6_IndelRealigner()
		if 'baserecalibrator' in jobs:
			self.Step7_BaseRecalibrator()
		if 'depthqc' in jobs:
			graphs = True if 'graph' in jobs else False
			self.Step8_bamQC(graphs=graphs)
		if 'cnv' in jobs:
			self.final_tsv.append(os.path.join(self.workdir.root, 'cnv', self.sample, '%s.cnv.anno.tsv' % self.sample))
		if 'haplotypecaller' in jobs:
			self.Step8_VariationCaller(methods='HaplotypeCaller')
		elif 'unifiedgenotyper' in jobs:
			self.Step8_VariationCaller(methods='UnifiedGenotyper')
		if 'variantfiltration' in jobs:
			self.Step9_VariantFiltration()
		if 'annotation' in jobs:
			self.Step10_Annotation()
		if 'result' in jobs:
			self.Step13_Excel()

	def Step1_Filter(self):
		"""
		Step1 filter adapter, QC
		"""
		filter_tools = SOAPnuke()
		parameters = dict(((i, j) for i, j in self.conf.items('Filter Parameter') if j))
		parameters['clean_fq_type'] = self.conf.get('Sequencing data', 'outputQualitySystem') or 'sanger'
		parameters['qual_sys'] = self.conf.get('Sequencing data', 'qualitySystem') or 'illumina'
		parameters['seq_type'] = self.conf.get('Sequencing data', 'fqnameType') or 'new'
		for lane_number, fastq in self.messages.fq.SequenceData.iteritems():
			command = list()
			lane_name = '%s.lane.%d' % (self.sample, lane_number)
			s_out = os.path.join(self.workdir.Script, "Step1.Filter.{0}.sh".format(lane_name))
			bash = BASH(self.sample, s_out, self.log)
			symdir = os.path.join(self.workdir.RawData, lane_name)
			outdir = os.path.join(self.workdir.CleanData, lane_name)
			qcdir = os.path.join(self.workdir.QC, lane_name)
			parameters['outdir'] = outdir
			if not os.path.exists(symdir):
				os.makedirs(symdir)
			if not os.path.exists(outdir):
				os.makedirs(outdir)
			if not os.path.exists(qcdir):
				os.makedirs(qcdir)
			parameters['fq1'] = fastq[0][0]
			parameters['clean_fq1'] = "%s.lane.%d.clean.1.fq.gz" % (self.sample, lane_number)
			mksymlink(parameters['fq1'], os.path.join(symdir, os.path.basename(parameters['fq1'])))
			if fastq[0][1]:
				parameters['adapter1'] = fastq[0][1]
				mksymlink(parameters['adapter1'], os.path.join(symdir, os.path.basename(parameters['adapter1'])))
			else:
				parameters['adapter1'] = None
			if len(fastq) == 2:
				parameters['fq2'] = fastq[1][0]
				mksymlink(parameters['fq2'], os.path.join(symdir, os.path.basename(parameters['fq2'])))
				parameters['clean_fq2'] = "%s.lane.%d.clean.2.fq.gz" % (self.sample, lane_number)
				if fastq[1][1]:
					parameters['adapter2'] = fastq[1][1]
					mksymlink(parameters['adapter2'], os.path.join(symdir, os.path.basename(parameters['adapter2'])))
				else:
					parameters['adapter2'] = None
			command.append(bash.stat_command_formact(filter_tools.filter(**parameters),
			                                         'Step1 filter lane %d' % lane_number))
			command.append("mv %s/*.txt %s" % (outdir, qcdir))
			bash.write(bash.bash_header_and_foot(command, 'Step1 filter lane %d' % lane_number))
			bash.close()

	def Step2_Alignment(self):
		"""
		Step2 alignment, gender_check
		"""
		default_model = 'aln' if self.messages.fq.SequenceType == 'SE' else 'PE'
		aln_generate = 'samse' if self.messages.fq.SequenceType == 'SE' else 'sampe'
		max_threads = self.conf.get('Alignment Parameter', 'max_threads') or 4
		model = self.conf.get('Alignment Parameter', 'Algorithm') or default_model
		alignment_tools = BWA(max_threads=max_threads)
		samtools = Samtools()
		picard = Picard(jar_path=os.path.join(Rhea_Chip_Home, "tools", "picard"),
		                javatmp=os.path.join(self.workdir.Alignment, '../../javatmp'))
		reads_groups = r"@RG\tID:FAMILY_{0}\tSM:{1}\tLB:{2}\tPL:ILLUMINA\tPU:{3}".format(self.messages.Family,
		                                                                                 self.messages.Sample,
		                                                                                 self.messages.Library,
		                                                                                 self.messages.Unit)
		male_ref = self.conf.get('Reference databases', 'male_ref')
		female_ref = self.conf.get('Reference databases', 'female_ref')
		options = self.conf.get('Alignment Parameter', 'parameter_alignment') or ""

		for lane_number, fastq in self.messages.fq.SequenceData.iteritems():
			command = list()
			lane_name = '%s.lane.%d' % (self.sample, lane_number)
			fq_list = [os.path.join(self.workdir.CleanData, lane_name, "%s.clean.1.fq.gz" % lane_name)]
			if len(fastq) == 2:
				fq_list.append(os.path.join(self.workdir.CleanData, lane_name, "%s.clean.2.fq.gz" % lane_name))
			output_bam = os.path.join(self.workdir.Alignment, "%s.raw.bam" % lane_name)
			s_out = os.path.join(self.workdir.Script, "Step2.Alignment.{0}.sh".format(lane_name))
			bash = BASH(self.sample, s_out, self.log)
			if model == "mem":
				cd = alignment_tools.mem(" ".join(fq_list), male_ref, other_options=options, readgroup=reads_groups)
				cd += samtools.view(output_file=output_bam)
				cd = bash.stat_command_formact(cd, 'Step2 mem lane %d' % lane_number)
				command.append(cd)
			else:
				for fq in range(len(fq_list)):
					sai = fq_list[fq] + '.sai'
					cd = alignment_tools.aln(fq_list[fq], male_ref, sai, other_options=options)
					cd = bash.stat_command_formact(cd, 'Step2 aln lane %d fastq %d' % (lane_number, fq))
					command.append(cd)
				if aln_generate == "sampe":
					cd = alignment_tools.sampe(" ".join([fq + '.sai' for fq in fq_list]), " ".join(fq_list), male_ref,
					                           readgroup=reads_groups)
				else:
					cd = alignment_tools.samse(" ".join([fq + '.sai' for fq in fq_list]), " ".join(fq_list), male_ref,
					                           readgroup=reads_groups)
				cd += samtools.view(output_file=output_bam)
				cd = bash.stat_command_formact(cd, 'Step2 aln lane %d' % lane_number)
				command.append(cd)
			sort_bam = os.path.join(self.workdir.Alignment, "%s.sort.bam" % lane_name)
			cd = picard.SortSam(output_bam, out_bam=sort_bam)
			cd = bash.stat_command_formact(cd, 'Step2 SortBam lane %d' % lane_number)
			command.append(cd)
			gender_file = os.path.join(self.workdir.QC, "%s.gender" % lane_name)
			cd = "bam2gender.py {0} {1}".format(sort_bam, gender_file)
			cd = bash.stat_command_formact(cd, 'Step2 gender check lane %d' % lane_number)
			command.append(cd)
			command.append("rm %s\n" % output_bam)
			command.append("gender=`awk '{print $2}' %s`\n" % gender_file)
			if model == "mem":
				cd = alignment_tools.mem(" ".join(fq_list), female_ref, other_options=options, readgroup=reads_groups)
				cd += samtools.view(output_file=output_bam)
				cd = bash.stat_command_formact(cd, 'Step2 Re-mem lane %d' % lane_number, level=2)
			else:
				for fq in fq_list:
					sai = fq + '.sai'
					cd = alignment_tools.aln(fq, male_ref, sai, other_options=options)
					cd = bash.stat_command_formact(cd, 'Step2 aln lane %d' % lane_number, level=2)
					command.append('if [ $gender == female ]; then\n\t %s \n\t' % cd)
				if aln_generate == "sampe":
					cd = alignment_tools.sampe(" ".join([fq + '.sai' for fq in fq_list]), " ".join(fq_list), male_ref,
					                           readgroup=reads_groups)
				else:
					cd = alignment_tools.samse(" ".join([fq + '.sai' for fq in fq_list]), " ".join(fq_list), male_ref,
					                           readgroup=reads_groups)
				cd += samtools.view(output_file=output_bam)
				cd = bash.stat_command_formact(cd, 'Step2 Re-aln lane %d' % lane_number, level=2)
			command.append('if [ $gender == female ]; then\n\t %s \n' % cd)
			cd = picard.SortSam(output_bam, out_bam=sort_bam)
			cd = bash.stat_command_formact(cd, 'Step2 Re-SortBam lane %d' % lane_number, level=2)
			command.append('\t%s \n\trm %s\nfi' % (cd, output_bam))
			bash.write(bash.bash_header_and_foot(command, "Step2 Alignment lane %d" % lane_number))
			bash.close()

	def Step3_MergeBam(self):
		"""
		Step3 bam merge
		"""
		bash = BASH(self.sample, os.path.join(self.workdir.Script, "Step3.merge.sh"), self.log)
		sort_bam_list = [os.path.join(self.workdir.Alignment, "%s.lane.%d.sort.bam" % (self.sample, lane_number))
		                 for lane_number in sorted(self.messages.fq.SequenceData.keys())]
		picard = Picard(jar_path=os.path.join(Rhea_Chip_Home, "tools", "picard"),
		                javatmp=os.path.join(self.workdir.Alignment, '../../javatmp'))
		input_bam = " ".join(sort_bam_list)
		output_bam = os.path.join(self.workdir.Alignment, '%s.final.bam' % self.sample)
		cd = picard.MergeSamFiles(input=input_bam, output=output_bam)
		cd = bash.stat_command_formact(cd, 'Step3 MergeBam %s' % self.sample)
		command = [cd, "rm -f %s %s\n\n" % (input_bam, ' '.join([bam + '.bai' for bam in sort_bam_list]))]
		samtools = Samtools()
		cd = samtools.index(output_bam)
		command.append(bash.stat_command_formact(cd, 'Step3 index %s' % output_bam))
		bash.write(bash.bash_header_and_foot(command, "Step3 merge bam"))
		bash.close()

	def Step4_removeduplicates(self):
		"""
		Step4 Mark duplicate
		"""
		command = list()
		bash = BASH(self.sample, os.path.join(self.workdir.Script, "Step4.removeduplicates.sh"), self.log)
		max_memory = self.conf.get('removeduplicates Parameter', 'max_memory') or None
		max_file_handles = self.conf.get('removeduplicates Parameter', 'max_file_handles') or 8000
		picard = Picard(jar_path=os.path.join(Rhea_Chip_Home, "tools", "picard"),
		                javatmp=os.path.join(self.workdir.Alignment, '../../javatmp'),
		                max_memory=max_memory)
		final_bam = os.path.join(self.workdir.Alignment, '%s.final.bam' % self.sample)
		dupmark_bam = os.path.join(self.workdir.Alignment, '%s.sort.dup.bam' % self.sample)
		metrics_file = os.path.join(self.workdir.QC, '%s.dup.metrics' % self.sample)
		cd = picard.MarkDuplicates(final_bam, out_bam=dupmark_bam,
		                           max_file_handles=max_file_handles,
		                           metrics_file=metrics_file)
		command.append(bash.stat_command_formact(cd, 'Step4 MarkDuplicates %s' % final_bam))
		cd = picard.FixMateInformation(in_bam=dupmark_bam, out_bam=final_bam)
		command.append(bash.stat_command_formact(cd, 'Step4 FixMateInformation %s' % dupmark_bam))
		command.append("rm -f {0} {1}\n\n".format(dupmark_bam, final_bam + '.bai'))
		samtools = Samtools()
		cd = samtools.index(final_bam)
		command.append(bash.stat_command_formact(cd, 'Step4 index %s' % final_bam))
		bash.write(bash.bash_header_and_foot(command, "Step4 MarkDuplicates"))
		bash.close()

	def Step5_RealignerTargetCreator(self):
		"""
		Step5 RealignerTargetCreator
		"""
		bash = BASH(self.sample, os.path.join(self.workdir.Script, "Step5.RealignerTargetCreator.sh"), self.log)
		max_memory = self.conf.get('Realignment Parameter', 'max_memory') or None
		gatk = GATK3(jar=os.path.join(Rhea_Chip_Home, "tools", "GATK3", "GenomeAnalysisTK.jar"),
		             javatmp=os.path.join(self.workdir.Alignment, '../../javatmp'),
		             max_memory=max_memory)
		parameters = dict(((i, j) for i, j in self.conf.items('Realignment Parameter') if j))
		parameters['reference'] = self.conf.get('Reference databases', 'male_ref')
		parameters['in_bam'] = os.path.join(self.workdir.Alignment, '%s.final.bam' % self.sample)
		parameters['target_intervals'] = os.path.join(self.workdir.Alignment, '%s.realn_data.intervals' % self.sample)
		parameters['regions'] = self.conf.get('Personal Analysis', 'run_region')
		cd = bash.stat_command_formact(gatk.RealignerTargetCreator(**parameters), 'Step5 RealignerTargetCreator')
		bash.write(bash.bash_header_and_foot(cd, "Step5 RealignerTargetCreator"))
		bash.close()

	def Step6_IndelRealigner(self):
		"""
		Step6 IndelRealigner
		"""
		command = list()
		bash = BASH(self.sample, os.path.join(self.workdir.Script, "Step6.IndelRealigner.sh"), self.log)
		max_memory = self.conf.get('IndelRealigner Parameter', 'max_memory') or None
		gatk = GATK3(jar=os.path.join(Rhea_Chip_Home, "tools", "GATK3", "GenomeAnalysisTK.jar"),
		             javatmp=os.path.join(self.workdir.Alignment, '../../javatmp'),
		             max_memory=max_memory)
		parameters = dict(((i, j) for i, j in self.conf.items('IndelRealigner Parameter') if j))
		parameters['reference'] = self.conf.get('Reference databases', 'male_ref')
		parameters['in_bam'] = os.path.join(self.workdir.Alignment, '%s.final.bam' % self.sample)
		parameters['output'] = os.path.join(self.workdir.Alignment, '%s.sort.realn.bam' % self.sample)
		parameters['target_intervals'] = os.path.join(self.workdir.Alignment, '%s.realn_data.intervals' % self.sample)
		cd = bash.stat_command_formact(gatk.IndelRealigner(**parameters), 'Step6 IndelRealigner')
		command.append(cd)
		cd = 'rm {0}\nmv {1} {2}\nmv {3} {4}\n'.format(parameters['target_intervals'], parameters['output'],
		                                               parameters['in_bam'],
		                                               os.path.join(self.workdir.Alignment,
		                                                            "{0:s}.sort.realn.bai".format(self.sample)),
		                                               parameters['in_bam'] + '.bai')
		command.append(cd)
		bash.write(bash.bash_header_and_foot(command, "Step6 IndelRealigner"))
		bash.close()

	def Step7_BaseRecalibrator(self):
		"""
		Step7 BaseRecalibrator, PrintReads
		"""
		command = list()
		bash = BASH(self.sample, os.path.join(self.workdir.Script, "Step7.BaseRecalibrator.sh"), self.log)
		max_memory = self.conf.get('Baserecal Parameter', 'max_memory') or None
		gatk = GATK3(jar=os.path.join(Rhea_Chip_Home, "tools", "GATK3", "GenomeAnalysisTK.jar"),
		             javatmp=os.path.join(self.workdir.Alignment, '../../javatmp'),
		             max_memory=max_memory)
		parameters = dict(((i, j) for i, j in self.conf.items('Baserecal Parameter') if j))
		parameters['recal_data'] = os.path.join(self.workdir.Alignment, '%s.recal_data.grp' % self.sample)
		parameters['reference'] = self.conf.get('Reference databases', 'male_ref')
		parameters['in_bam'] = os.path.join(self.workdir.Alignment, '%s.final.bam' % self.sample)
		parameters['regions'] = self.conf.get('Personal Analysis', 'run_region')
		cd = bash.stat_command_formact(gatk.BaseRecalibrator(**parameters), 'Step7 BaseRecalibrator')
		command.append(cd)
		out_bam = os.path.join(self.workdir.Alignment, '%s.recal_data.bam' % self.sample)
		cd = bash.stat_command_formact(gatk.PrintReads(parameters['reference'], parameters['in_bam'],
		                                               parameters['recal_data'], output=out_bam,
		                                               max_threads=parameters.get('max_threads', None)),
		                               'Step7 PrintReads')
		command.append(cd)
		cd = 'rm {0}\nmv {1} {2}\nmv {3} {4}\n'.format(parameters['recal_data'], out_bam,
		                                               parameters['in_bam'],
		                                               os.path.join(self.workdir.Alignment,
		                                                            '%s.recal_data.bai' % self.sample),
		                                               parameters['in_bam'] + '.bai')
		command.append(cd)
		bash.write(bash.bash_header_and_foot(command, "Step7 BaseRecalibrator"))
		bash.close()

	def Step8_VariationCaller(self, methods='HaplotypeCaller'):
		"""
		Step6 variation call
		:param methods: Variation Caller
		"""
		bash = BASH(self.sample, os.path.join(self.workdir.Script, "Step8.%s.sh" % methods), self.log)
		max_memory = self.conf.get('%s Parameter' % methods, 'max_memory') or None
		gatk = GATK3(jar=os.path.join(Rhea_Chip_Home, "tools", "GATK3", "GenomeAnalysisTK.jar"),
		             javatmp=os.path.join(self.workdir.Alignment, '../../javatmp'),
		             max_memory=max_memory)
		parameters = dict(((i, j) for i, j in self.conf.items('%s Parameter' % methods) if j))
		parameters['output'] = os.path.join(self.workdir.Variation, '%s.raw.vcf' % self.sample)
		parameters['reference'] = self.conf.get('Reference databases', 'male_ref')
		parameters['in_bam'] = os.path.join(self.workdir.Alignment, '%s.final.bam' % self.sample)
		parameters['regions'] = self.conf.get('Personal Analysis', 'run_region')
		if methods == 'UnifiedGenotyper':
			cd = gatk.UnifiedGenotyper(**parameters)
		else:
			cd = gatk.HaplotypeCaller(**parameters)
		cd = bash.stat_command_formact(cd, "Step8 %s" % methods)
		bash.write(bash.bash_header_and_foot(cd, "Step8 %s" % methods))
		bash.close()

	def Step8_bamQC(self, graphs=True):
		self.final_tsv.append(os.path.join(self.workdir.QC, "depthAnno/Target", "%s.Rmdup.uncover.anno" % self.sample))
		bash = BASH(self.sample, os.path.join(self.workdir.Script, "Step8.depthQC.sh"), self.log)
		depthqc = DepthQC()
		parameters = dict(((i, j) for i, j in self.conf.items('bamQC Parameter') if j))
		parameters['outdir'] = self.workdir.QC
		parameters['in_bam'] = os.path.join(self.workdir.Alignment, '%s.final.bam' % self.sample)
		parameters['plot'] = graphs
		parameters['reference'] = self.conf.get('Reference databases', 'male_ref')
		parameters['target_bed'] = self.conf.get('Personal Analysis', 'target_region')
		parameters['flankbed'] = self.conf.get('Personal Analysis', 'run_region')
		parameters['trans'] = self.conf.get('Personal Analysis', 'trans_list')
		parameters['genes'] = self.conf.get('Personal Analysis', 'gene_list')
		cd = depthqc.run(**parameters)
		cd = bash.stat_command_formact(cd, 'Step8 bam QC')
		bash.write(bash.bash_header_and_foot(cd, "Step8 bam QC"))
		bash.close()

	def Step9_VariantFiltration(self):
		"""
		Step9 filter, phasing
		"""
		command = list()
		bash = BASH(self.sample, os.path.join(self.workdir.Script, "Step9.VariantFiltration.sh"), self.log)
		max_memory = self.conf.get('VariantFiltration Parameter', 'max_memory') or None
		gatk = GATK3(jar=os.path.join(Rhea_Chip_Home, "tools", "GATK3", "GenomeAnalysisTK.jar"),
		             javatmp=os.path.join(self.workdir.Alignment, '../../javatmp'),
		             max_memory=max_memory)
		in_vcf = os.path.join(self.workdir.Variation, '%s.raw.vcf' % self.sample)
		reference = self.conf.get('Reference databases', 'male_ref')
		varfilter = self.conf.get('VariantFiltration Parameter', 'varfilter') or None
		max_threads = self.conf.get('VariantFiltration Parameter', 'max_threads') or 0
		merge_option = self.conf.get('VariantFiltration Parameter', 'merge_option') or "UNSORTED"
		filter_tag = self.conf.get('VariantFiltration Parameter', 'filter_tag') or "StandardFilter"
		in_bam = os.path.join(self.workdir.Alignment, '%s.final.bam' % self.sample)
		for i in ('SNP', 'INDEL'):
			var_expression = self.conf.get('VariantFiltration Parameter', '%sfilterExpression' % i) or None
			cd = gatk.SelectVariants(reference, in_vcf,
			                         os.path.join(self.workdir.Variation, "{0}.raw.{1}.vcf".format(self.sample,
			                                                                                       i.lower())),
			                         vartype=i, varfilter=varfilter, max_threads=max_threads)
			cd = bash.stat_command_formact(cd, 'Step9 Select %s' % i)
			command.append(cd)
			cd = gatk.VariantFiltration(reference,
			                            os.path.join(self.workdir.Variation,
			                                         "{0}.raw.{1}.vcf".format(self.sample, i.lower())),
			                            os.path.join(self.workdir.Variation,
			                                         "{0}.{1}.vcf".format(self.sample, i.lower())),
			                            var_expression, filter_tag=filter_tag)
			cd = bash.stat_command_formact(cd, 'Step9 VariantFiltration %s' % i)
			command.append(cd)
		snv = os.path.join(self.workdir.Variation, "%s.snv.vcf" % self.sample)
		indel = os.path.join(self.workdir.Variation, "%s.indel.vcf" % self.sample)
		cd = gatk.ReadBackedPhasing(reference, in_bam, os.path.join(self.workdir.Variation,
		                                                            "%s.snp.vcf" % self.sample), snv)
		cd = bash.stat_command_formact(cd, 'Step9 snv phasing')
		command.append(cd)
		cd = gatk.CombineVariants(reference, "{0} {1}".format(snv, indel),
		                          os.path.join(self.workdir.Variation, "%s.vcf" % self.sample),
		                          max_threads=max_threads, merge_option=merge_option)
		cd = bash.stat_command_formact(cd, 'Step9 vcf combine')
		command.append(cd)
		for vcf in [snv, indel]:
			command.append("bgzip -f {0}\ntabix -f -p vcf {0}.gz\n".format(vcf))
		cd = "vcf_phasing.py {0} {1} {2}".format(in_bam,
		                                         os.path.join(self.workdir.Variation, "%s.vcf" % self.sample),
		                                         os.path.join(self.workdir.Variation, "%s.final.vcf.gz" % self.sample))
		cd = bash.stat_command_formact(cd, 'Step9 vcf phasing')
		command.append(cd)
		command.append("rm -rf {0}/*.vcf {0}/*.idx\n".format(self.workdir.Variation))
		bash.write(bash.bash_header_and_foot(command, "Step9 VariantFiltration"))
		bash.close()

	def Step10_Annotation(self):
		"""
		Step10 VCF Annotation
		"""
		command = list()
		bash = BASH(self.sample, os.path.join(self.workdir.Script, "Step10.Annotation.sh"), self.log)
		max_memory = self.conf.get('Annotation Parameter', 'max_memory') or None
		snpeff = snpEff(jar=os.path.join(Rhea_Chip_Home, "tools", "snpEff", "snpEff.jar"),
		                javatmp=os.path.join(self.workdir.Alignment, '../../javatmp'),
		                max_memory=max_memory)
		vcf = os.path.join(self.workdir.Variation, "%s.final.vcf.gz" % self.sample)
		eff = os.path.join(self.workdir.Annotation, "%s.snpEffAnno.vcf" % self.sample)
		stats = os.path.join(self.workdir.Annotation, "%s.AnnoStats.html" % self.sample)
		parameters = dict(((i, j) for i, j in self.conf.items('Annotation Parameter') if j))
		cd = snpeff.VariantAnnotator(vcf, output=eff, stats=stats, **parameters)
		cd = bash.stat_command_formact(cd, 'Step10 snpEff Anno %s' % vcf)
		command.append(cd)
		command.append("bgzip -f {0} \ntabix -f -p vcf {0}.gz\n".format(eff))
		parameters['transfile'] = self.conf.get('Personal Analysis', 'trans_list') or None
		parameters['genesfile'] = self.conf.get('Personal Analysis', 'gene_list') or None
		cd = "AnnotateVCF.py -v {0}.gz -o {1} ".format(eff, self.workdir.Annotation)
		if parameters['transfile']:
			cd += "-t %s " % parameters['transfile']
		if parameters['genesfile']:
			cd += "-g %s " % parameters['genesfile']
		if "usedb" in parameters and parameters["usedb"]:
			cd += '--usedb \"%s\" ' % parameters['usedb']
		if "kickout_function" in parameters and parameters["kickout_function"]:
			cd += '--kickout_function \"%s\" ' % parameters['kickout_function']
		if "ignoredb" in parameters and parameters["ignoredb"]:
			cd += '--ignore \"%s\" ' % parameters['ignoredb']
		if "follow_function" in parameters and parameters["follow_function"]:
			cd += '--follow_function \"%s\" ' % parameters['follow_function']
		cd = bash.stat_command_formact(cd, 'Step10 vcf annovar')
		command.append(cd)
		command.append("rm -f {0}.gz {0}.gz.tbi \n\n".format(eff))
		self.final_tsv.insert(0, os.path.join(self.workdir.Annotation, self.sample + ".anno.tsv.gz"))
		bash.write(bash.bash_header_and_foot(command, "Step10 VCFAnnotations"))
		bash.close()

	def Step13_Excel(self):
		"""
		Step13 Excel out
		"""
		parameters = dict(((i, j) for i, j in self.conf.items('Result Parameter') if j))
		bash = BASH(self.sample, os.path.join(self.workdir.Script, "Step13.result.sh"), self.log)
		format_file = parameters["excel_report_out_format"]
		cd = "tsv2xlsx.py -o {0} -r {1} {2}".format(os.path.join(self.workdir.Annotation, self.sample + ".final.xlsx"),
		                                            format_file, " ".join(self.final_tsv))
		cd = bash.stat_command_formact(cd, 'Step11 excel output')
		bash.write(bash.bash_header_and_foot(cd, "Step11 excel output"))
		bash.close()


def process(samples, configs, prepair_dir, project_name=None):
	outdir = prepair_dir.rootdir
	family_or_single = max([len(s) for s in samples.family.values()]) > 1
	sample_tuple = namedtuple('workdir', ("root", "QC", "Script", "RawData", "CleanData",
	                                      "Alignment", "Variation", "Annotation"))
	project_name = str(project_name) if project_name else os.path.basename(outdir)
	job_client = os.path.join(outdir, 'script', "start.%s.sh" % project_name)
	bash = BASH(project_name, job_client)
	job = configs.get('Analysis Flow', 'analysis_option') or configs.get('Analysis Flow', 'Rhea_Flow_analysis')
	jobs = job.strip().lower().split(",")
	command = list()
	for family, sample_set in samples.family.iteritems():
		qc_path = os.path.join(outdir, 'doc/QC', family) if family_or_single else os.path.join(outdir, 'doc/QC')
		sc_path = os.path.join(outdir, 'script', family) if family_or_single else os.path.join(outdir, 'script')
		if not os.path.exists(qc_path):
			os.makedirs(qc_path)
		if not os.path.exists(sc_path):
			os.makedirs(sc_path)
		for sample in sample_set:
			logger.info("Preparing the whole analysis pipeline for sample : %s" % sample)
			sample_qc_dir = os.path.join(qc_path, sample)
			sample_sc_dir = os.path.join(sc_path, sample)
			sample_fq_dir = os.path.join(outdir, 'fq/raw_data', sample)
			sample_cfq_dir = os.path.join(outdir, 'fq/clean_data', sample)
			sample_vc_dir = os.path.join(outdir, 'variation', sample)
			sample_anno_dir = os.path.join(outdir, 'annotation', sample)
			sample_alig_dir = os.path.join(outdir, 'alignment', sample)
			nametuple = (outdir, sample_qc_dir, sample_sc_dir, sample_fq_dir, sample_cfq_dir,
			             sample_alig_dir, sample_vc_dir, sample_anno_dir)
			for d in nametuple:
				if not os.path.exists(d):
					os.makedirs(d)
			dirs = sample_tuple._make(nametuple)
			messages = samples.messages[sample]
			sc = Pipeline(messages, dirs, configs)
			sc.get_scripts(jobs)
	cmd = "JobClient.py -s {0} -c {1} -d {2}".format(os.path.join(outdir, 'doc/sample.list'),
	                                                 os.path.join(outdir, 'doc', 'Rhea_Chip.conf'),
	                                                 os.path.join(outdir, 'script'))
	if 'cnv' in jobs:
		parameters = dict(((i, j) for i, j in configs.items('CNV Parameter') if j))
		parameters['samplelist'] = os.path.join(outdir, 'doc/sample.list')
		parameters['outdir'] = os.path.join(outdir, 'cnv')
		if not os.path.isdir(parameters['outdir']):
			os.makedirs(parameters['outdir'])
		parameters['reference'] = configs.get('Reference databases', 'male_ref')
		parameters['region'] = configs.get('Personal Analysis', 'run_region')
		parameters['depths'] = os.path.join(outdir, 'doc/QC')
		if 'repeatdb' not in parameters:
			parameters['repeatdb'] = os.path.join(Rhea_Chip_Home, "db/RepeatMasker/rmsk.bed.gz")
		if 'dbdir' not in parameters:
			parameters['dbdir'] = os.path.join(Rhea_Chip_Home, "db")
		if 'winlen' not in parameters:
			parameters['winlen'] = 30
		if 'siftlen' not in parameters:
			parameters['siftlen'] = 25
		cd = "cnv_pipeline.py -b {0} -l {1} -q {2} -o {3} -r {4} -d {5} -R {6} -w {7} -s {8} ".format(
			parameters['region'], parameters['samplelist'], parameters['depths'], parameters['outdir'],
			parameters['repeatdb'], parameters['dbdir'], parameters['reference'], parameters['winlen'],
			parameters['siftlen'])
		cd += "-p\n\n" if 'graph' in jobs else "\n\n"
		command.append(cd)
		cmd += " --CNV %s" % os.path.join(outdir, 'cnv/script')
	command.append(cmd)
	bash.write(bash.bash_header_and_foot(command, "Pipeline Runs"))
	bash.close()
	return job_client


def main():
	usage = 'Usage: %prog [-h] [--version] --samplelist [sample list] --config [config file] [options]'
	description = Rhea_Chip.__description__
	author = Rhea_Chip.__author__
	version = Rhea_Chip.__version__
	parser = OptionParser(usage=usage, version=version, description=description, epilog=author)
	expect = OptionGroup(parser, 'Expected arguments', 'Caution: These parameters are necessary for Rhea_Chip.')
	expect.add_option('-s', '--samplelist', metavar='FILE', dest='samplelist',
	                  help=r'''The sample list file
	                        Column 1:    sample name
	                        Column 2:    family name
	                        Column 3:    library
	                        Column 4:    FQ file [formact:
	                                                 lane1/fq1:lane1/adapter1;lane1/fq2:lane1/adapter2|
	                                                 lane2/fq1:lane2/adapter1;lane2/fq2:lane2/adapter2|...]
	                        Column 5:    case/control''')
	expect.add_option('-c', '--config', metavar='FILE', dest='config',
	                  help='The config file, contain all specific settings')
	parser.add_option_group(expect)
	optinal = OptionGroup(parser, 'Optional arguments', 'Caution: If you do not set these parameters in addition,'
	                                                    ' Rhea_Chip will select the default value.')
	optinal.add_option('-o', '--outdir', dest='outdir', default=os.getcwd(),
	                   help='The output dir [ default: %s ]' % os.getcwd())
	optinal.add_option('-p', '--project_name', dest='project_name', help='set your project name', default=None)
	parser.add_option_group(optinal)
	options, args = parser.parse_args()
	if not options.samplelist or not options.config:
		parser.print_help()
		return 'Expected arguments lost !!!'
	samplelist = os.path.abspath(options.samplelist)
	config = os.path.abspath(options.config)
	outdir = os.path.abspath(options.outdir)
	logger.info("Rhea_Chip Tasks initialization !")
	logger.info("Parser the setting config file !")
	baseconfig = ParserConfig(config)
	config_stat = baseconfig.config_check()
	if config_stat != "Success":
		return config_stat
	logger.info("Parser the Sample list file !")
	samples = SampleMessageParser(samplelist)
	logger.info("Total {0} sample(s) in our analysis !".format(len(samples)))
	prepair_dir = FolderMaker(outdir)
	logger.info("Create the whole working directory !")
	prepair_dir.create_subdirectory(['alignment', 'doc', 'doc/QC', 'fq', 'fq/raw_data', 'cnv',
	                                 'fq/clean_data', 'javatmp', 'script', 'variation', 'annotation'])
	baseconfig.config_save(os.path.join(outdir, 'doc', 'Rhea_Chip.conf'))
	job_client = process(samples, baseconfig.handle, prepair_dir)
	open(os.path.join(outdir, 'doc', 'Rhea_Chip.log'), "wb").write(open(LogFile, "rb").read())
	if samplelist != os.path.join(outdir, 'doc', 'sample.list'):
		open(os.path.join(outdir, 'doc', 'sample.list'), "wb").write(open(samplelist, "rb").read())
	return "All scripts have been generated, Next, please run : %s" % job_client


if __name__ == "__main__":
	sys.exit(main())
